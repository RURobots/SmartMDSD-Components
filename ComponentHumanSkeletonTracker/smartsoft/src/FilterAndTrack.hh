//--------------------------------------------------------------------------
// Code generated by the SmartSoft MDSD Toolchain
// The SmartSoft Toolchain has been developed by:
//  
// Service Robotics Research Center
// University of Applied Sciences Ulm
// Prittwitzstr. 10
// 89075 Ulm (Germany)
//
// Information about the SmartSoft MDSD Toolchain is available at:
// www.servicerobotik-ulm.de
//
// This file is generated once. Modify this file to your needs. 
// If you want the toolchain to re-generate this file, please 
// delete it before running the code generator.
//--------------------------------------------------------------------------
#ifndef _FILTERANDTRACK_HH
#define _FILTERANDTRACK_HH

#include <limits>
#include <opencv2/opencv.hpp>

#define RUR_StandAloneMathsLibrary
#include "KalmanFilterWithoutControls.h"

#include "FilterAndTrackCore.hh"

// Openpose and opencv include files
#include "openpose/headers.hpp"

#define PROCESS_VARIANCE 		1.0
#define MEASUREMENT_VARIANCE 	0.5

class FilterAndTrack  : public FilterAndTrackCore
{
	enum KinectJoint
	{
		KinectSpineBase =		0,
		KinectSpineMid =		1,
		KinectNeck =			2,
		KinectHead =			3,
		KinectShoulderLeft =	4,
		KinectElbowLeft =		5,
		KinectWristLeft =		6,
		KinectHandLeft =		7,
		KinectShoulderRight =	8,
		KinectElbowRight =		9,
		KinectWristRight =		10,
		KinectHandRight =		11,
		KinectHipLeft =			12,
		KinectKneeLeft =		13,
		KinectAnkleLeft =		14,
		KinectFootLeft =		15,
		KinectHipRight =		16,
		KinectKneeRight =		17,
		KinectAnkleRight =		18,
		KinectFootRight =		19,
		KinectSpineShoulder =	20,
		KinectHandTipLeft =		21,
		KinectThumbLeft =		22,
		KinectHandTipRight =	23,
		KinectThumbRight =		24,
	};

	enum OpJoint
	{
		OpHead =				0,
		OpSpineShoulder =		1,
		OpShoulderRight =		2,
		OpElbowRight =			3,
		OpWristRight =			4,
		OpShoulderLeft =		5,
		OpElbowLeft =			6,
		OpWristLeft =			7,
		OpSpineBase =			8,
		OpHipRight =			9,
		OpKneeRight =			10,
		OpAnkleRight =			11,
		OpHipLeft =				12,
		OpKneeLeft =			13,
		OpAnkleLeft =			14,
		OpEyeRight =			15,
		OpEyeLeft =				16,
		OpEarRight =			17,
		OpEarLeft =   			18,
		OpFootLeft =			19,
		OpToeLeft =				20,
		OpHeelLeft =			21,
		OpFootRight =			22,
		OpToeRight =			23,
		OpHeelRight = 			24
	};

protected:
	int maxNumberOfBodies;
	int depthRegionSize;

	static const int numberOfJoints = 25;


	// The needed camera instrics data
	float widthFocalLength;						// The focal length of the camera in the horizontal direction
	float heightFocalLength;					// The focal length of the camera in the vertical direction
	float widthPricipalAxis;					// The centre of the image (principal axis) in the horizontal direction
	float heightPricipalAxis;					// The centre of the image (principal axis) in the vertical direction

	// Member variables needed for the Kalman filtering
	bool firstTime;

	static const int numberOfStates = 6;
	static const int numberOfMeasurements = 3;

	RUR_RobotMaths::Matrix a;
	RUR_RobotMaths::Matrix c;
	RUR_RobotMaths::Matrix q;
	RUR_RobotMaths::Matrix r;

	RUR_RobotMaths::KalmanFilterWithoutControls* filter[6][numberOfJoints];

	RUR_RobotMaths::Vector* x[6][numberOfJoints];			// The state is X, Y, Z, vel X, vel Y, vel Z
	RUR_RobotMaths::Matrix* cov[6][numberOfJoints];

	RUR_RobotMaths::Vector z;											// The measurements are X, Y, Z

	const double timeStep;
	double lastMeasurementTime[6][numberOfJoints];
	const double measurementVariance;
	const double processVariance;
	RUR_RobotMaths::Matrix newCov;

	DomainHumanTracking::CommHumanPositionsAndVelocities lastSensorData;
	DomainHumanTracking::CommHumanPositionsAndVelocities thisSensorData;

private:
	virtual void on_RGBDImagePushServiceIn(const DomainVision::CommRGBDImage &input);
public:
	FilterAndTrack(SmartACE::SmartComponent *comp);
	virtual ~FilterAndTrack();
	
	virtual int on_entry();
	virtual int on_execute();
	virtual int on_exit();

private:
	void printKeypoints(const std::shared_ptr<std::vector<std::shared_ptr<op::Datum>>>& datumsPtr);
	void display(const std::shared_ptr<std::vector<std::shared_ptr<op::Datum>>>& datumsPtr, cv::Mat& depthImage);

	void extractOpenPoseColourImage(const DomainVision::CommRGBDImage &input, cv::Mat& cvImage, op::Matrix& openPoseImage);
	DomainVision::DepthFormatType extractCvDepthImage(const DomainVision::CommRGBDImage& input, cv::Mat& openCvImage);
	void convert2dTo3d(int x, int y, cv::Mat& cvDepthImage, DomainVision::DepthFormatType depthFormat, float& x3d, float& y3d, float& z3d);
	void markDepthImage(int x, int y, cv::Mat& cvDepthImage, DomainVision::DepthFormatType depthFormat);
	void convertOpenPoseToKinect(DomainHumanTracking::CommBodyData& bodyData);
	DomainHumanTracking::CommJointData interpolateJoint(DomainHumanTracking::CommJointData firstJoint, DomainHumanTracking::CommJointData secondJoint, double scale);
	void calculateVelocitiesKalman(DomainHumanTracking::CommHumanPositionsAndVelocities* lastSensorData, DomainHumanTracking::CommHumanPositionsAndVelocities* thisSensorData, float timeDifference, float maximumVelocity);
	long long int convertToUsecs(CommBasicObjects::CommTimeStamp timeStamp);

	template <typename T> T findMinimumDepth(int x, int y, cv::Mat& cvDepthImage)
	{
		T returnValue = std::numeric_limits<T>::max();

		for (int xRange = x - depthRegionSize / 2; xRange <= x + depthRegionSize / 2; xRange++)
		{
			for (int yRange = y - depthRegionSize / 2; yRange <= y + depthRegionSize / 2; yRange++)
			{
				try
				{
					if ((cvDepthImage.at<T>(cv::Point(xRange, yRange)) != 0) && (cvDepthImage.at<T>(cv::Point(xRange, yRange)) < returnValue))
					{
						returnValue = cvDepthImage.at<T>(cv::Point(xRange, yRange));
					}
				}
				catch(...)
				{}
			}
		}

		return returnValue;
	}

	op::Wrapper opWrapper;
};

#endif
